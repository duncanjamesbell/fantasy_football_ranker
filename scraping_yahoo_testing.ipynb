{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-26 15:52:10,784 DEBUG] [yahoo_oauth.oauth.__init__] Checking \n",
      "[2023-04-26 15:52:10,800 DEBUG] [yahoo_oauth.oauth.token_is_valid] ELAPSED TIME : 3944821.396823406\n",
      "[2023-04-26 15:52:10,801 DEBUG] [yahoo_oauth.oauth.token_is_valid] TOKEN HAS EXPIRED\n",
      "[2023-04-26 15:52:10,805 DEBUG] [yahoo_oauth.oauth.refresh_access_token] REFRESHING TOKEN\n"
     ]
    }
   ],
   "source": [
    "from tkinter import S\n",
    "import yahoo_fantasy_api as yfa\n",
    "from yahoo_oauth import OAuth2\n",
    "import pandas as pd\n",
    "import json\n",
    "from get_chrome_driver import GetChromeDriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "#connect to the yahoo API\n",
    "#this oauth file must have been generated by me, not sure the instructions to do so.  probably easy.\n",
    "oauth = OAuth2(None, None, from_file='oauth2.json')\n",
    "\n",
    "#API docs: https://yahoo-fantasy-api.readthedocs.io/en/latest/yahoo_fantasy_api.html\n",
    "football = yfa.game.Game(oauth, 'nfl')\n",
    "\n",
    "leagues = football.league_ids()\n",
    "l = football.to_league(leagues[-3]) #sample league for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather leagues associated with my account\n",
    "leagues = football.league_ids()\n",
    "\n",
    "for league in leagues:\n",
    "    try:\n",
    "        #load the latest data that we've processed\n",
    "        league_master_df = pd.read_csv('league_df_master.csv')\n",
    "        loaded_leagues = list(league_master_df.league_key)\n",
    "    except:\n",
    "        #we need to start new\n",
    "        loaded_leagues = []\n",
    "    if league not in loaded_leagues:\n",
    "        print(f'Appending league {league} to league_df')\n",
    "        league_settings=football.to_league(league).settings()\n",
    "        league_df = pd.DataFrame(league_settings)\n",
    "        try:\n",
    "            league_df_new = pd.concat([league_master_df,league_df])\n",
    "        except:\n",
    "            league_df_new = league_df.copy()\n",
    "        league_df_new.reset_index(drop=True,inplace=True)\n",
    "        league_df_new.to_csv('league_df_master.csv',index=False)#now export the latest file in case we are interrupted\n",
    "\n",
    "leagues_df = pd.read_csv('league_df_master.csv') #load the full dataset\n",
    "leagues_df.reset_index(inplace=True,drop=True)\n",
    "print('Leagues df created')\n",
    "\n",
    "#assemble managers for each league\n",
    "#this cell takes a few minutes to run\n",
    "    \n",
    "managers = []\n",
    "for league in leagues:\n",
    "    try:\n",
    "        #we'll cache the latest data here to enable picking up from where we left off\n",
    "        managers_master_df = pd.read_csv('managers_df_master.csv')\n",
    "        managers_master_df.drop_duplicates(inplace=True)\n",
    "        loaded_manager_leagues = list(managers_master_df.league_key)\n",
    "    except:\n",
    "        #we need to start new\n",
    "        loaded_manager_leagues = []\n",
    "    if league not in loaded_manager_leagues:\n",
    "        print(f'Appending managers for league {league}')\n",
    "        lg = football.to_league(league)\n",
    "        for k in lg.teams().keys():\n",
    "            team = lg.teams()[k]\n",
    "            manager = lg.teams()[k]['managers'][0]['manager']\n",
    "            try:\n",
    "                faab = team['faab_balance']\n",
    "            except:\n",
    "                faab = ''\n",
    "            try:\n",
    "                felo_score = manager['felo_score']\n",
    "            except:\n",
    "                felo_score = ''\n",
    "            try:\n",
    "                draft_grade = team['draft_grade']\n",
    "            except:\n",
    "                draft_grade = ''\n",
    "            managers.append((k,league, lg.settings()['season'],lg.settings()['name'],team['team_id'],team['name'],manager['nickname'],felo_score,team['url'],draft_grade,team['number_of_moves'],faab,team['number_of_trades'],team['roster_adds']['coverage_value']))\n",
    "        manager_df = pd.DataFrame(managers,columns=['l_manager_key','league_key','season','league_name','team_id','team','manager','felo_score','url','draft_grade','number_of_moves','number_of_trades','faab_balance','roster_adds'])\n",
    "        try:\n",
    "            new_manager_df = pd.concat([managers_master_df,manager_df])\n",
    "        except:\n",
    "            new_manager_df = manager_df.copy()\n",
    "        new_manager_df.to_csv('managers_df_master.csv',index=False)\n",
    "\n",
    "manager_df = pd.read_csv('managers_df_master.csv') #load the full dataset\n",
    "manager_df.drop_duplicates(inplace=True)\n",
    "manager_df.reset_index(inplace=True,drop=True)\n",
    "print('Managers lists assembled')\n",
    "\n",
    "#group leagues together if manager membership meets threshold\n",
    "match_threshold = .75\n",
    "\n",
    "league_keys = []\n",
    "for key in manager_df.l_manager_key:\n",
    "    league_keys.append('.'.join(key.split('.')[:-2]))\n",
    "manager_df['league_key'] = league_keys\n",
    "\n",
    "manager_df.sort_values(by=['season','league_name'],ascending=False,inplace=True)\n",
    "seasons_df = manager_df[['league_key','season','league_name']].copy()\n",
    "seasons_df.drop_duplicates(subset=['season','league_name'],inplace=True) #could use season_id for this?\n",
    "seasons = []\n",
    "for index, row in seasons_df.iterrows():\n",
    "    seasons.append((row['season'],row['league_name'],row['league_key']))\n",
    "league_profiles = {}\n",
    "league_mappings = []\n",
    "i=0\n",
    "print('Grouping seasons...')\n",
    "for s in seasons:\n",
    "    print(s)\n",
    "    matched = False\n",
    "    s_league_df = manager_df[(manager_df.season == s[0]) & (manager_df.league_name == s[1])]\n",
    "    if len(league_profiles)==0:\n",
    "        historical_managers = []\n",
    "        historical_teams = []\n",
    "        for index, row in s_league_df.iterrows():\n",
    "            if row['manager'] != '-- hidden --':\n",
    "                historical_managers.append(row['manager'])\n",
    "            if row['team'] != '-- hidden --':\n",
    "                historical_teams.append(row['team'])\n",
    "        league_profiles[i] = (s_league_df,historical_managers,historical_teams) #creating the first profile which is the most recent season \n",
    "        league_mappings.append((s[2],i))\n",
    "        i=i+1\n",
    "    else:\n",
    "        for l in league_profiles.keys(): #compare current league to set of already identified league classes\n",
    "            if matched == False:\n",
    "                profile_managers = league_profiles[l][1].copy()\n",
    "                profile_teams = league_profiles[l][2].copy()\n",
    "                match_score = 0\n",
    "                for index, row in s_league_df.iterrows():\n",
    "                    if row['manager'] in profile_managers:\n",
    "                        #print(row['manager'])\n",
    "                        match_score = match_score + 1\n",
    "                    elif row['team'] in profile_teams:\n",
    "                        #print(row['team'])\n",
    "                        match_score = match_score + 1\n",
    "                    #updating profile lists in case we need to update the dictionary\n",
    "                    if (row['manager'] != '-- hidden --') & (row['manager'] not in profile_managers):\n",
    "                        profile_managers.append(row['manager'])\n",
    "                    if (row['team'] != '-- hidden --') & (row['team'] not in profile_teams):\n",
    "                        profile_teams.append(row['team'])\n",
    "                if match_score / s_league_df.shape[0] > match_threshold:\n",
    "                    #print(match_score / s_league_df.shape[0])\n",
    "                    league_mappings.append((s[2], l))\n",
    "                    league_profiles[l] = (league_profiles[l][0],profile_managers,profile_teams) #update dictionary with latest names\n",
    "                    matched = True\n",
    "        #we assume there were no matches, so create a new profile\n",
    "        if matched == False:\n",
    "            league_profiles[i] = (s_league_df, list(s_league_df['manager']), list(s_league_df['team']))\n",
    "            #print(f\"new profile: {i}\")\n",
    "            #print(league_profiles[i])\n",
    "            league_mappings.append((s[2],i))\n",
    "            i=i+1\n",
    "\n",
    "season_dict = {}\n",
    "for m in league_mappings:\n",
    "    season_dict[m[0]] = m[1]\n",
    "\n",
    "league_ids = []\n",
    "for league_key in leagues_df.league_key:\n",
    "    league_ids.append(season_dict[league_key])\n",
    "leagues_df['group_id'] = league_ids\n",
    "\n",
    "leagues_df.sort_values(by=['group_id','season'],ascending=[True,False],inplace=True)\n",
    "leagues_df.drop_duplicates(subset=['season','group_id'])[['name','season','group_id']]\n",
    "\n",
    "#assemble all standings data for all leagues\n",
    "standings = []\n",
    "for league in leagues:\n",
    "    l = football.to_league(league)\n",
    "    standings.append((league,l.standings()))\n",
    "\n",
    "standings_dfs = []\n",
    "for s in standings:\n",
    "\n",
    "    #method to compile standings data (minus faab)\n",
    "    standings_df = pd.DataFrame(s[1])\n",
    "\n",
    "    dfs=[]\n",
    "    for a in standings_df.outcome_totals.values:\n",
    "        a_df = pd.DataFrame([a])\n",
    "        dfs.append(a_df)\n",
    "    array_df = pd.concat(dfs)\n",
    "    array_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    full_standings = pd.merge(standings_df,array_df,left_index=True,right_index=True)\n",
    "\n",
    "    #get moves and faab from manager_df\n",
    "    moves = []\n",
    "    faab_budget = []\n",
    "    for manager in full_standings.team_key:\n",
    "        moves.append(manager_df[manager_df.l_manager_key==manager].number_of_moves.values[0])\n",
    "        faab_budget.append(manager_df[manager_df.l_manager_key==manager].faab_balance.values[0])\n",
    "    full_standings['moves'] = moves\n",
    "    full_standings['faab_balance'] = faab_budget\n",
    "    full_standings['league_key'] = s[0]\n",
    "    standings_dfs.append(full_standings)\n",
    "standings_master = pd.concat(standings_dfs)\n",
    "#standings_master.to_csv('standings_master.csv', index=False)\n",
    "\n",
    "#playoff wins\n",
    "playoff_dfs = []\n",
    "for season in standings_master.league_key:\n",
    "    season_df = standings_master[standings_master.league_key==season].copy()\n",
    "    num_managers = season_df.shape[0]\n",
    "    playoff_wins = []\n",
    "    for index, row in season_df.iterrows():\n",
    "        try:\n",
    "            rank = int(row['rank'])\n",
    "            seed = int(row['playoff_seed'])\n",
    "            if num_managers == 10:\n",
    "                if rank == 1:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(2)\n",
    "                    else:\n",
    "                        playoff_wins.append(3)\n",
    "                elif rank == 2:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(1)\n",
    "                    else:\n",
    "                        playoff_wins.append(2)\n",
    "                elif rank == 3:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(1)\n",
    "                    else:\n",
    "                        playoff_wins.append(2)\n",
    "                elif rank == 4:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(0)\n",
    "                    else:\n",
    "                        playoff_wins.append(1)\n",
    "                elif rank == 5:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 6:\n",
    "                    playoff_wins.append(0)\n",
    "                elif rank == 7:\n",
    "                    playoff_wins.append(2)\n",
    "                elif rank == 8:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 9:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 10:\n",
    "                    playoff_wins.append(0)\n",
    "            elif num_managers == 8:\n",
    "                if rank == 1:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(2)\n",
    "                    else:\n",
    "                        playoff_wins.append(3)\n",
    "                elif rank == 2:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(1)\n",
    "                    else:\n",
    "                        playoff_wins.append(2)\n",
    "                elif rank == 3:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(1)\n",
    "                    else:\n",
    "                        playoff_wins.append(2)\n",
    "                elif rank == 4:\n",
    "                    if seed <= 2:\n",
    "                        playoff_wins.append(0)\n",
    "                    else:\n",
    "                        playoff_wins.append(1)\n",
    "                elif rank == 5:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 6:\n",
    "                    playoff_wins.append(0)\n",
    "                elif rank == 7:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 8:\n",
    "                    playoff_wins.append(0)\n",
    "            elif num_managers == 6:\n",
    "                if rank == 1:\n",
    "                    playoff_wins.append(2)\n",
    "                elif rank == 2:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 3:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 4:\n",
    "                    playoff_wins.append(0)\n",
    "                elif rank == 5:\n",
    "                    playoff_wins.append(1)\n",
    "                elif rank == 6:\n",
    "                    playoff_wins.append(0)\n",
    "        except:\n",
    "            #this is a band-aid, it should really be based on the number of managers in league.  \n",
    "            #I'm assuming that this group is all cases where there are two spots outside the playoffs\n",
    "            try:\n",
    "                if int(row['rank']) == 7:\n",
    "                    playoff_wins.append(1)\n",
    "                elif int(row['rank']) == 8:\n",
    "                    playoff_wins.append(0)\n",
    "                elif int(row['rank']) == 9:\n",
    "                    playoff_wins.append(1)\n",
    "                elif int(row['rank']) == 10:\n",
    "                    playoff_wins.append(0)\n",
    "                else:\n",
    "                    playoff_wins.append('')\n",
    "            except:\n",
    "                playoff_wins.append('')\n",
    "    season_df['playoff_wins'] = playoff_wins\n",
    "    playoff_dfs.append(season_df)\n",
    "playoff_df = pd.concat(playoff_dfs)\n",
    "playoff_df.drop_duplicates(subset=['team_key'],inplace=True) #I do not know why this is required but aparently dups are created above\n",
    "\n",
    "playoff_df[['rank','playoff_seed','playoff_wins']]  \n",
    "#playoff_df.to_csv('playoff_wins_testing.csv',index=False)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver.quit()\n",
    "except:\n",
    "    pass\n",
    "from get_chrome_driver import GetChromeDriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--log-level=3\")\n",
    "#chrome_options.add_argument('--headless')\n",
    "#chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "import time\n",
    "\n",
    "# Install the driver:\n",
    "# Downloads ChromeDriver for the installed Chrome version on the machine\n",
    "# Adds the downloaded ChromeDriver to path\n",
    "try:\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "except:\n",
    "    get_driver = GetChromeDriver()\n",
    "    get_driver.install()\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Use the installed ChromeDriver with Selenium\n",
    "yahoo_profile_url = 'https://profiles.sports.yahoo.com/user/5ES5NWOA3D4IPAP4H73VCTBDDM/?sport=football'\n",
    "username = 'iflyhighsky'\n",
    "driver.get(yahoo_profile_url)\n",
    "time.sleep(2)\n",
    "\n",
    "#find the history button\n",
    "buttons=driver.find_elements(By.TAG_NAME,\"button\")\n",
    "for button in buttons:\n",
    "    try:\n",
    "        if button.text == 'History':\n",
    "            history_button = button\n",
    "    except:\n",
    "        pass \n",
    "history_button.click()\n",
    "time.sleep(1)\n",
    "\n",
    "#collect league urls\n",
    "football_urls = []\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "for a in soup.find_all('a'):\n",
    "    url = a.get('href')\n",
    "    if ('football.fantasysports.yahoo.com/' in url) and ('/f1/') in url:\n",
    "        football_urls.append(url)\n",
    "\n",
    "football_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather content for a season \n",
    "league_url = 'https://football.fantasysports.yahoo.com/2007/f1/580505' #2007\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2009/f1/790872' #2009\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2010/f1/438659' #2010\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2011/f1/211725' #2011\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2012/f1/324073' #2012 \n",
    "league_url = 'https://football.fantasysports.yahoo.com/2013/f1/378899' #2013\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2014/f1/329823' #2014\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2015/f1/216667' #2015\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2016/f1/370526' #2016\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2017/f1/347949' #2017\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2018/f1/153194' #2018\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2019/f1/102231' #2019\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2020/f1/523631' #2020\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2021/f1/696126' #2021\n",
    "league_url = 'https://football.fantasysports.yahoo.com/2022/f1/709240' #2022\n",
    "#url= 'https://football.fantasysports.yahoo.com/f1/1399238'\n",
    "\n",
    "driver.get(league_url)\n",
    "time.sleep(2)\n",
    "try:\n",
    "    driver.find_element(By.XPATH,\"//label[@for='login-username']\") #if this succeeds then we assume login is being requested\n",
    "    print('Login required...')\n",
    "    username_input = driver.find_element(By.XPATH,\"//input[@id='login-username']\")\n",
    "    username = 'iflyhighsky'\n",
    "    username_input.send_keys(username)\n",
    "    next_button = driver.find_element(By.XPATH,\"//input[@value='Next']\")\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    send_button = driver.find_element(By.XPATH,\"//button[@name='send']\")\n",
    "    send_button.click()\n",
    "    print('NOW - CHECK YOUR PHONE AND TAKE US THE REST OF THE WAY')\n",
    "except:\n",
    "    print('Login was not required')\n",
    "    pass\n",
    "\n",
    "# WE NEED TO COLLECT:\n",
    "# FAAB SPEND\n",
    "# WEEKLY PLAYER SCORES SO I CAN PARSE POINTS FROM DRAFTED VS PI?  CKUPS\n",
    "# OVERALL PLAYER SCORES SO I CAN RANK THEM....ACTUALY DO I NEED THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect schedule urls\n",
    "schedule_url = driver.find_element(By.XPATH,\"//a[@data-target='#lhstschedtab']\").get_attribute('href')\n",
    "driver.get(schedule_url)\n",
    "\n",
    "schedule_nav_html = driver.find_element(By.XPATH,\"//ul[@id='schedsubnav']\").get_attribute('innerHTML')\n",
    "schedule_nav_soup = BeautifulSoup(schedule_nav_html)\n",
    "nav_elems = schedule_nav_soup.find_all('li')\n",
    "\n",
    "manager_schedule_urls = []\n",
    "for n in nav_elems:\n",
    "    elem_url = 'https://football.fantasysports.yahoo.com/' + n.find('a',href=True).get('href')\n",
    "    manager = n.text.strip()\n",
    "    manager_schedule_urls.append((manager, elem_url))\n",
    "\n",
    "#collect weekly matchup urls\n",
    "manager_matchup_urls = []\n",
    "for m in manager_schedule_urls:\n",
    "    print(f'Collecting matchup urls for {m[0]}')\n",
    "    driver.get(m[1])\n",
    "\n",
    "    #find the urls for weekly\n",
    "    table_html = driver.find_element(By.XPATH,\"//table[@class='Table Table-interactive']\").get_attribute('innerHTML')\n",
    "    table_soup = BeautifulSoup(table_html)\n",
    "    table_elems = table_soup.find_all('tr')\n",
    "\n",
    "    matchup_urls = []\n",
    "    for t in table_elems:\n",
    "        for a in t.find_all('a'):\n",
    "            try:\n",
    "                url = a.get('href')\n",
    "                if 'matchup' in url:\n",
    "                    matchup_urls.append('https://football.fantasysports.yahoo.com/' + url)\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "    manager_matchup_urls.append((m[0],matchup_urls))\n",
    "\n",
    "manager_matchup_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now getting weekly matchup data\n",
    "def get_matchup_data(matchup_url):\n",
    "    left_matchup_id = matchup_url.split('mid1=')[1].split('&')[0]\n",
    "    right_matchup_id = matchup_url.split('mid2=')[1]\n",
    "    driver.get(matchup_url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    matchup_link_elems = driver.find_elements(By.XPATH,'//a[@class=\"F-link\"]')\n",
    "    left_manager = matchup_link_elems[0].text\n",
    "    left_manager_url = matchup_link_elems[0].get_attribute('href')\n",
    "    left_manager_url_id = left_manager_url.split('/')[-1]\n",
    "    right_manager = matchup_link_elems[1].text\n",
    "    right_manager_url = matchup_link_elems[1].get_attribute('href')\n",
    "    right_manager_url_id = right_manager_url.split('/')[-1]\n",
    "\n",
    "    if left_matchup_id == left_manager_url_id:\n",
    "        manager_match = 'left'\n",
    "        opponent_id = right_manager_url_id\n",
    "    elif left_matchup_id == right_manager_url_id:\n",
    "        manager_match = 'right'\n",
    "        opponent_id = left_manager_url_id\n",
    "    else:\n",
    "        print('Error when matching manager ID')\n",
    "\n",
    "    week_results_html = driver.find_element(By.XPATH,\"//table[@id='statTable1']\").get_attribute('innerHTML')\n",
    "    matchup_soup = BeautifulSoup(week_results_html)\n",
    "\n",
    "    starter_positions = []\n",
    "    for p in matchup_soup.find_all(\"td\",{\"class\":\"Va-top Bg-shade F-shade Ta-c\"}):\n",
    "        if 'TOTAL' not in p.text:\n",
    "            starter_positions.append(p.text)\n",
    "\n",
    "    matchup_players = matchup_soup.find_all(\"div\", {\"class\": \"ysf-player-name Nowrap Grid-u Relative Lh-xs Ta-start\"})\n",
    "    left_players = []\n",
    "    right_players = []\n",
    "    n=0\n",
    "    for m in matchup_players:\n",
    "        try:\n",
    "            player_name = m.text\n",
    "            player_url = m.find('a').get('href')\n",
    "        except:\n",
    "            player_name = ''\n",
    "            player_url = ''\n",
    "        if n == 0:\n",
    "            left_players.append((player_name,player_url))\n",
    "            n = 1\n",
    "        else:\n",
    "            right_players.append((player_name,player_url))\n",
    "            n = 0\n",
    "\n",
    "    left_week_scores = matchup_soup.find_all(\"td\",{\"class\":\"Pend-lg Ta-end Fw-b Nowrap Va-top\"})\n",
    "    right_week_scores = matchup_soup.find_all(\"td\",{\"class\":\"Ta-end Fw-b Nowrap Va-top\"})\n",
    "\n",
    "    week_df = pd.DataFrame(starter_positions,columns=['position'])\n",
    "    week_df['manager_id'] = left_matchup_id\n",
    "    week_df['opponent_id'] = opponent_id\n",
    "    week_df['matchup_url'] = matchup_url\n",
    "    if manager_match == 'left':\n",
    "        scores = []\n",
    "        for s in left_week_scores:\n",
    "            scores.append(s.text)\n",
    "        scores = scores[:-1]\n",
    "        week_df[['player','player_url']] = left_players\n",
    "        week_df['score'] = scores\n",
    "    elif manager_match == 'right':\n",
    "        scores = []\n",
    "        for s in right_week_scores:\n",
    "            scores.append(s.text)\n",
    "        scores = scores[:-1]\n",
    "        week_df[['player','player_url']] = right_players\n",
    "        week_df['score'] = scores   \n",
    "\n",
    "    time.sleep(1) \n",
    "\n",
    "    return week_df\n",
    "\n",
    "manager_week_dfs = []\n",
    "for m in manager_matchup_urls:\n",
    "    week_dfs = []\n",
    "    manager = m[0]\n",
    "    for matchup_url in m[1]:\n",
    "        week_dfs.append(get_matchup_data(matchup_url))\n",
    "    full_manager_week_df = pd.concat(week_dfs)\n",
    "    full_manager_week_df['manager'] = manager\n",
    "    manager_week_dfs.append(full_manager_week_df)\n",
    "full_weekly_data_df = pd.concat(manager_week_dfs)\n",
    "full_weekly_data_df['league_url'] = league_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_weekly_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_weekly_data_df.to_csv('2022_pre_matchups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_league_urls = ['https://football.fantasysports.yahoo.com/2007/f1/580505',\n",
    "'https://football.fantasysports.yahoo.com/2009/f1/790872',\n",
    "'https://football.fantasysports.yahoo.com/2010/f1/438659',\n",
    "'https://football.fantasysports.yahoo.com/2011/f1/211725',\n",
    "'https://football.fantasysports.yahoo.com/2012/f1/324073',\n",
    "'https://football.fantasysports.yahoo.com/2013/f1/378899',\n",
    "'https://football.fantasysports.yahoo.com/2014/f1/329823',\n",
    "'https://football.fantasysports.yahoo.com/2015/f1/216667',\n",
    "'https://football.fantasysports.yahoo.com/2016/f1/370526',\n",
    "'https://football.fantasysports.yahoo.com/2017/f1/347949',\n",
    "'https://football.fantasysports.yahoo.com/2018/f1/153194',\n",
    "'https://football.fantasysports.yahoo.com/2019/f1/102231',\n",
    "'https://football.fantasysports.yahoo.com/2020/f1/523631',\n",
    "'https://football.fantasysports.yahoo.com/2021/f1/696126',\n",
    "'https://football.fantasysports.yahoo.com/2022/f1/709240']\n",
    "pre_league_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_url = 'https://football.fantasysports.yahoo.com/2022/f1/709240'\n",
    "driver.get(league_url)\n",
    "#get playoff matchup urls\n",
    "driver.execute_script(\"window.scrollTo(0, 700)\") \n",
    "grid_panes = driver.find_elements(By.XPATH,\"//div[@class='Grid-u-1-3 Ta-c']\")\n",
    "if len(grid_panes) == 0:\n",
    "    #handling 6p leagues\n",
    "    grid_panes = driver.find_elements(By.XPATH,\"//div[@class='Grid-u-1-2 Ta-c']\")\n",
    "\n",
    "quarterfinals = grid_panes[0].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket quarterfinal']\")\n",
    "if len(quarterfinals) > 0:\n",
    "    grid_index_modifier = 0\n",
    "else:\n",
    "    grid_index_modifier = 1\n",
    "semifinals = grid_panes[1 - grid_index_modifier].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket semifinal']\")\n",
    "fifth_place = grid_panes[1 - grid_index_modifier].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket place_5']\")\n",
    "finals = grid_panes[2 - grid_index_modifier].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket final']\")\n",
    "third_place = grid_panes[2 - grid_index_modifier].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket place_3']\")\n",
    "\n",
    "playoff_matchup_urls = []\n",
    "if grid_index_modifier == 0:\n",
    "    sections = [quarterfinals, semifinals, fifth_place, third_place, finals]\n",
    "else:\n",
    "    sections = [semifinals, fifth_place, third_place, finals]\n",
    "for section in sections:\n",
    "    for e in section:\n",
    "        matchup_path = e.get_attribute('data-target')\n",
    "        matchup_url = 'https://football.fantasysports.yahoo.com' + matchup_path\n",
    "        playoff_matchup_urls.append(matchup_url)\n",
    "\n",
    "#now switch to consolation\n",
    "consolation_matchup_urls = []\n",
    "consolidation_elem = driver.find_element(By.CSS_SELECTOR,\"span[id='selectlist_nav']\")\n",
    "consolidation_elem.click()\n",
    "action = webdriver.ActionChains(driver)\n",
    "action.move_to_element(consolidation_elem)\n",
    "action.move_by_offset(0, 50)    # 0px to the right, 50px to bottom\n",
    "action.click()\n",
    "action.perform()\n",
    "time.sleep(1)\n",
    "\n",
    "grid_panes = driver.find_elements(By.XPATH,\"//div[@class='Grid-u-1-3 Ta-c']\")\n",
    "if len(grid_panes) == 0:\n",
    "    #handling 6p leagues\n",
    "    grid_panes = driver.find_elements(By.XPATH,\"//div[@class='Grid-u-1-2 Ta-c']\")\n",
    "    grid_index_modifier = 1\n",
    "consolation_semis = grid_panes[1 -grid_index_modifier].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket semifinal']\")\n",
    "for consolation_semi in consolation_semis:\n",
    "    matchup_path = consolation_semi.get_attribute('data-target')\n",
    "    matchup_url = 'https://football.fantasysports.yahoo.com' + matchup_path\n",
    "    consolation_matchup_urls.append(matchup_url)\n",
    "grid_panes = driver.find_elements(By.XPATH,\"//div[@class='Grid-u-1-3 Ta-c']\") #do it again to avoid stale element exception\n",
    "if len(grid_panes) == 0:\n",
    "    #handling 6p leagues\n",
    "    grid_panes = driver.find_elements(By.XPATH,\"//div[@class='Grid-u-1-2 Ta-c']\") \n",
    "    grid_index_modifier = 1\n",
    "seventh_place = grid_panes[2 - grid_index_modifier].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket place_7']\")\n",
    "ninth_place = grid_panes[2 - grid_index_modifier].find_elements(By.XPATH,\"div[@class='Linkable Bdr Bdr-radius Bg-shade Ta-start yfa-matchup bracket place_9']\")\n",
    "\n",
    "for section in [seventh_place,ninth_place]:\n",
    "    for e in section:\n",
    "        matchup_path = e.get_attribute('data-target')\n",
    "        matchup_url = 'https://football.fantasysports.yahoo.com' + matchup_path\n",
    "        consolation_matchup_urls.append(matchup_url)\n",
    "\n",
    "full_playoff_urls = playoff_matchup_urls + consolation_matchup_urls\n",
    "\n",
    "#now getting weekly matchup data\n",
    "def get_playoff_matchup_data(matchup_url):\n",
    "    left_matchup_id = matchup_url.split('mid1=')[1].split('&')[0]\n",
    "    right_matchup_id = matchup_url.split('mid2=')[1]\n",
    "    driver.get(matchup_url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    matchup_link_elems = driver.find_elements(By.XPATH,'//a[@class=\"F-link\"]')\n",
    "    left_manager = matchup_link_elems[0].text\n",
    "    left_manager_url = matchup_link_elems[0].get_attribute('href')\n",
    "    left_manager_url_id = left_manager_url.split('/')[-1]\n",
    "    right_manager = matchup_link_elems[1].text\n",
    "    right_manager_url = matchup_link_elems[1].get_attribute('href')\n",
    "    right_manager_url_id = right_manager_url.split('/')[-1]\n",
    "\n",
    "    week_results_html = driver.find_element(By.XPATH,\"//table[@id='statTable1']\").get_attribute('innerHTML')\n",
    "    matchup_soup = BeautifulSoup(week_results_html)\n",
    "\n",
    "    starter_positions = []\n",
    "    for p in matchup_soup.find_all(\"td\",{\"class\":\"Va-top Bg-shade F-shade Ta-c\"}):\n",
    "        if 'TOTAL' not in p.text:\n",
    "            starter_positions.append(p.text)\n",
    "\n",
    "    matchup_players = matchup_soup.find_all(\"div\", {\"class\": \"ysf-player-name Nowrap Grid-u Relative Lh-xs Ta-start\"})\n",
    "    left_players = []\n",
    "    right_players = []\n",
    "    n=0\n",
    "    for m in matchup_players:\n",
    "        try:\n",
    "            player_name = m.text\n",
    "            player_url = m.find('a').get('href')\n",
    "        except:\n",
    "            player_name = ''\n",
    "            player_url = ''\n",
    "        if n == 0:\n",
    "            left_players.append((player_name,player_url))\n",
    "            n = 1\n",
    "        else:\n",
    "            right_players.append((player_name,player_url))\n",
    "            n = 0\n",
    "\n",
    "    left_week_scores = matchup_soup.find_all(\"td\",{\"class\":\"Pend-lg Ta-end Fw-b Nowrap Va-top\"})\n",
    "    right_week_scores = matchup_soup.find_all(\"td\",{\"class\":\"Ta-end Fw-b Nowrap Va-top\"})\n",
    "\n",
    "    left_df = pd.DataFrame(starter_positions,columns=['position'])\n",
    "    left_df['manager_id'] = left_manager_url_id\n",
    "    left_df['opponent_id'] = right_manager_url_id\n",
    "    left_df['matchup_url'] = matchup_url\n",
    "    scores = []\n",
    "    for s in left_week_scores:\n",
    "        scores.append(s.text)\n",
    "    scores = scores[:-1]\n",
    "    left_df[['player','player_url']] = left_players\n",
    "    left_df['score'] = scores\n",
    "\n",
    "    right_df = pd.DataFrame(starter_positions,columns=['position'])\n",
    "    right_df['manager_id'] = right_manager_url_id\n",
    "    right_df['opponent_id'] = left_manager_url_id\n",
    "    right_df['matchup_url'] = matchup_url\n",
    "    scores = []\n",
    "    for s in right_week_scores:\n",
    "        scores.append(s.text)\n",
    "    scores = scores[:-1]\n",
    "    right_df[['player','player_url']] = right_players\n",
    "    right_df['score'] = scores   \n",
    "\n",
    "    time.sleep(1) \n",
    "\n",
    "    return [left_df,right_df]\n",
    "\n",
    "playoff_match_dfs = []\n",
    "for url in full_playoff_urls:\n",
    "    playoff_dfs = []\n",
    "    matchup_data = get_playoff_matchup_data(url)\n",
    "    left_right_matchups = pd.concat(matchup_data)\n",
    "    playoff_match_dfs.append(left_right_matchups)\n",
    "full_playoff_data_df = pd.concat(playoff_match_dfs)\n",
    "full_playoff_data_df['league_url'] = league_url\n",
    "\n",
    "full_playoff_data_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_playoff_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_playoff_data_df.to_csv('2022_pre_playoffs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now getting weekly matchup data\n",
    "def get_playoff_matchup_data(matchup_url):\n",
    "    left_matchup_id = matchup_url.split('mid1=')[1].split('&')[0]\n",
    "    right_matchup_id = matchup_url.split('mid2=')[1]\n",
    "    driver.get(matchup_url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    matchup_link_elems = driver.find_elements(By.XPATH,'//a[@class=\"F-link\"]')\n",
    "    left_manager = matchup_link_elems[0].text\n",
    "    left_manager_url = matchup_link_elems[0].get_attribute('href')\n",
    "    left_manager_url_id = left_manager_url.split('/')[-1]\n",
    "    right_manager = matchup_link_elems[1].text\n",
    "    right_manager_url = matchup_link_elems[1].get_attribute('href')\n",
    "    right_manager_url_id = right_manager_url.split('/')[-1]\n",
    "\n",
    "    week_results_html = driver.find_element(By.XPATH,\"//table[@id='statTable1']\").get_attribute('innerHTML')\n",
    "    matchup_soup = BeautifulSoup(week_results_html)\n",
    "\n",
    "    starter_positions = []\n",
    "    for p in matchup_soup.find_all(\"td\",{\"class\":\"Va-top Bg-shade F-shade Ta-c\"}):\n",
    "        if 'TOTAL' not in p.text:\n",
    "            starter_positions.append(p.text)\n",
    "\n",
    "    matchup_players = matchup_soup.find_all(\"div\", {\"class\": \"ysf-player-name Nowrap Grid-u Relative Lh-xs Ta-start\"})\n",
    "    left_players = []\n",
    "    right_players = []\n",
    "    n=0\n",
    "    for m in matchup_players:\n",
    "        try:\n",
    "            player_name = m.text\n",
    "            player_url = m.find('a').get('href')\n",
    "        except:\n",
    "            player_name = ''\n",
    "            player_url = ''\n",
    "        if n == 0:\n",
    "            left_players.append((player_name,player_url))\n",
    "            n = 1\n",
    "        else:\n",
    "            right_players.append((player_name,player_url))\n",
    "            n = 0\n",
    "\n",
    "    left_week_scores = matchup_soup.find_all(\"td\",{\"class\":\"Pend-lg Ta-end Fw-b Nowrap Va-top\"})\n",
    "    right_week_scores = matchup_soup.find_all(\"td\",{\"class\":\"Ta-end Fw-b Nowrap Va-top\"})\n",
    "\n",
    "    left_df = pd.DataFrame(starter_positions,columns=['position'])\n",
    "    left_df['manager_id'] = left_manager_url_id\n",
    "    left_df['opponent_id'] = right_manager_url_id\n",
    "    left_df['matchup_url'] = matchup_url\n",
    "    scores = []\n",
    "    for s in left_week_scores:\n",
    "        scores.append(s.text)\n",
    "    scores = scores[:-1]\n",
    "    left_df[['player','player_url']] = left_players\n",
    "    left_df['score'] = scores\n",
    "\n",
    "    right_df = pd.DataFrame(starter_positions,columns=['position'])\n",
    "    right_df['manager_id'] = right_manager_url_id\n",
    "    right_df['opponent_id'] = left_manager_url_id\n",
    "    right_df['matchup_url'] = matchup_url\n",
    "    scores = []\n",
    "    for s in right_week_scores:\n",
    "        scores.append(s.text)\n",
    "    scores = scores[:-1]\n",
    "    right_df[['player','player_url']] = right_players\n",
    "    right_df['score'] = scores   \n",
    "\n",
    "    time.sleep(1) \n",
    "\n",
    "    return [left_df,right_df]\n",
    "\n",
    "playoff_match_dfs = []\n",
    "for url in full_playoff_urls:\n",
    "    playoff_dfs = []\n",
    "    matchup_data = get_playoff_matchup_data(url)\n",
    "    left_right_matchups = pd.concat(matchup_data)\n",
    "    playoff_match_dfs.append(left_right_matchups)\n",
    "full_playoff_data_df = pd.concat(playoff_match_dfs)\n",
    "full_playoff_data_df['league_url'] = league_url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_matchups = []\n",
    "playoff_matchups = []\n",
    "for year in [2007,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022]:\n",
    "    rs = pd.read_csv(f'{year}_pre_matchups.csv')\n",
    "    playoffs = pd.read_csv(f'{year}_pre_playoffs.csv')\n",
    "    rs_matchups.append(rs)\n",
    "    playoff_matchups.append(playoffs)\n",
    "\n",
    "all_regular_season = pd.concat(rs_matchups)\n",
    "all_playoffs = pd.concat(playoff_matchups)\n",
    "\n",
    "#add some features for regular season\n",
    "scores=[]\n",
    "league_ids = []\n",
    "manager_keys = []\n",
    "for index, row in all_regular_season.iterrows():\n",
    "    league_id = row['league_url'].split('/')[-1]\n",
    "    league_ids.append(league_id)\n",
    "    manager_key = league_id + '.' + str(row['manager_id'])\n",
    "    manager_keys.append(manager_key)\n",
    "    try:\n",
    "        scores.append(float(row['score']))\n",
    "    except:\n",
    "        scores.append(0)\n",
    "    #should add player id too\n",
    "all_regular_season['league_id'] = league_ids\n",
    "all_regular_season['manager_key'] = manager_keys\n",
    "all_regular_season['score'] = scores\n",
    "\n",
    "#add some features for playoffs\n",
    "league_ids = []\n",
    "scores=[]\n",
    "manager_keys = []\n",
    "for index, row in all_playoffs.iterrows():\n",
    "    league_id = row['league_url'].split('/')[-1]\n",
    "    league_ids.append(league_id)\n",
    "    manager_key = league_id + '.' + str(row['manager_id'])\n",
    "    manager_keys.append(manager_key)\n",
    "    #should add player id too\n",
    "    try:\n",
    "        scores.append(float(row['score']))\n",
    "    except:\n",
    "        scores.append(0)\n",
    "all_playoffs['league_id'] = league_ids\n",
    "all_playoffs['manager_key'] = manager_keys\n",
    "all_playoffs['score']= scores\n",
    "\n",
    "#all_regular_season.to_csv('all_regular_season_thru_2022.csv',index=False)\n",
    "all_playoffs.to_csv('all_playoffs_thru_2022_revised.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regular_season = pd.read_csv('all_regular_season_thru_2022.csv')\n",
    "try:\n",
    "    all_regular_season.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#clean manager_key that I messed up with .1 and .10\n",
    "clean_manager_keys = []\n",
    "for index, row in all_regular_season.iterrows():\n",
    "    manager_key = str(row['league_id']) + '.' + str(row['manager_id'])\n",
    "    clean_manager_keys.append(manager_key)\n",
    "all_regular_season['manager_key'] = clean_manager_keys\n",
    "\n",
    "rs_groupby = all_regular_season[['manager_key','score']].groupby(['manager_key']).aggregate('sum')\n",
    "rs_groupby.rename(columns={'score':'rs_score'},inplace=True)\n",
    "rs_groupby.reset_index(inplace=True)\n",
    "rs_groupby['manager_key'] = rs_groupby['manager_key'].astype('str')\n",
    "\n",
    "standings_master_w_s=standings_master.merge(rs_groupby,left_on='manager_key',right_on='manager_key')\n",
    "standings_master_w_s['points_for'] = standings_master_w_s['points_for'].astype(float)\n",
    "standings_master_w_s['diff'] = standings_master_w_s['points_for'] - standings_master_w_s['rs_score']\n",
    "\n",
    "all_playoffs = pd.read_csv('all_playoffs_thru_2022.csv')\n",
    "\n",
    "#clean manager_key that I messed up with .1 and .10\n",
    "clean_manager_keys = []\n",
    "for index, row in all_playoffs.iterrows():\n",
    "    manager_key = str(row['league_id']) + '.' + str(row['manager_id'])\n",
    "    clean_manager_keys.append(manager_key)\n",
    "all_playoffs['manager_key'] = clean_manager_keys\n",
    "p_groupby = all_playoffs[['manager_key','score']].groupby(['manager_key']).aggregate('sum')\n",
    "p_groupby.rename(columns={'score':'p_score'},inplace=True)\n",
    "p_groupby.reset_index(inplace=True)\n",
    "\n",
    "consolidated_master = standings_master_w_s.merge(p_groupby,how='left', left_on='manager_key',right_on='manager_key')\n",
    "consolidated_master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append playoff wins that I neglected to include at earlier step...\n",
    "playoff_wins_dict = {}\n",
    "for index, row in playoff_df.iterrows():\n",
    "    playoff_wins_dict[row['team_key']] = row['playoff_wins']\n",
    "\n",
    "consolidated_master['playoff_wins'] = consolidated_master.team_key.map(playoff_wins_dict)\n",
    "consolidated_master.playoff_wins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_master.to_csv('consolidated_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge aggregations with standings master\n",
    "#add some keys we need to standings df\n",
    "team_ids = []\n",
    "league_ids = []\n",
    "manager_keys = []\n",
    "for index, row in standings_master.iterrows():\n",
    "    team_id = row['team_key'].split('.')[-1]\n",
    "    league_id = row['league_key'].split('.')[-1]\n",
    "    manager_key = league_id + '.' + team_id\n",
    "    team_ids.append(team_id)\n",
    "    league_ids.append(league_id)\n",
    "    manager_keys.append(manager_key)\n",
    "standings_master['team_id'] = team_ids\n",
    "standings_master['league_id'] = league_ids\n",
    "standings_master['manager_key'] = manager_keys\n",
    "\n",
    "standings_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_master = pd.read_csv('consolidated_master.csv')\n",
    "\n",
    "all_playoffs = pd.read_csv('all_playoffs_thru_2022_revised.csv')\n",
    "\n",
    "#clean manager_key that I messed up with .1 and .10\n",
    "clean_manager_keys = []\n",
    "for index, row in all_playoffs.iterrows():\n",
    "    manager_key = str(row['league_id']) + '.' + str(row['manager_id'])\n",
    "    clean_manager_keys.append(manager_key)\n",
    "all_playoffs['manager_key'] = clean_manager_keys\n",
    "p_groupby = all_playoffs[['manager_key','score']].groupby(['manager_key']).aggregate('sum')\n",
    "p_groupby.rename(columns={'score':'p_score'},inplace=True)\n",
    "p_groupby.reset_index(inplace=True)\n",
    "\n",
    "p_score_dict = {}\n",
    "for index, row in p_groupby.iterrows():\n",
    "    p_score_dict[row['manager_key']] = row['p_score']\n",
    "consolidated_master['manager_key'] = consolidated_master['manager_key'].astype(str)\n",
    "consolidated_master['p_score_revised'] = consolidated_master.manager_key.map(p_score_dict)\n",
    "consolidated_master.to_csv('consolidated_master_revised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_master.manager_key.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble all standings data for all leagues\n",
    "standings = []\n",
    "for league in leagues:\n",
    "    l = football.to_league(league)\n",
    "    standings.append((league,l.standings()))\n",
    "\n",
    "standings_dfs = []\n",
    "for s in standings:\n",
    "\n",
    "    #method to compile standings data (minus faab)\n",
    "    standings_df = pd.DataFrame(s[1])\n",
    "\n",
    "    dfs=[]\n",
    "    for a in standings_df.outcome_totals.values:\n",
    "        a_df = pd.DataFrame([a])\n",
    "        dfs.append(a_df)\n",
    "    array_df = pd.concat(dfs)\n",
    "    array_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    full_standings = pd.merge(standings_df,array_df,left_index=True,right_index=True)\n",
    "\n",
    "    #get moves and faab from manager_df\n",
    "    moves = []\n",
    "    faab_budget = []\n",
    "    for manager in full_standings.team_key:\n",
    "        moves.append(manager_df[manager_df.l_manager_key==manager].number_of_moves.values[0])\n",
    "        faab_budget.append(manager_df[manager_df.l_manager_key==manager].faab_balance.values[0])\n",
    "    full_standings['moves'] = moves\n",
    "    full_standings['faab_balance'] = faab_budget\n",
    "    full_standings['league_key'] = s[0]\n",
    "    standings_dfs.append(full_standings)\n",
    "standings_master = pd.concat(standings_dfs)\n",
    "standings_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_drafts = pd.read_excel('Historical draft.xlsx')\n",
    "lkup_concs = []\n",
    "for index, row in historical_drafts.iterrows():\n",
    "    lkup_concs.append(row['Standard name'] + row['Position'])\n",
    "historical_drafts['lkup_conc'] = lkup_concs\n",
    "\n",
    "names_dict_df = pd.read_csv('names_dict.csv')\n",
    "for index, row in names_dict_df.iterrows():\n",
    "    names_dict[row['player_conc']] = row['player_id']\n",
    "\n",
    "player_ids = []\n",
    "for s in historical_drafts['lkup_conc']:\n",
    "    try:\n",
    "        player_ids.append(names_dict[s])\n",
    "    except:\n",
    "        player_ids.append('')\n",
    "\n",
    "historical_drafts['player_id']= player_ids\n",
    "historical_drafts[historical_drafts.player_id == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now a process to ingest a NEW season's draft and calculate the relevant statistics that we will use\n",
    "draft = pd.read_excel('Draft Results/2021.xlsx')\n",
    "draft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "278252670ec473998422183e7c7c20bd7526adc6817e623fe2d4e128b05eb28d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
